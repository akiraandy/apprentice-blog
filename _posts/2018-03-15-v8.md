---
layout: post
title: "V8"
description: "Google's Open-source JavaScript Engine"
categories: [code]
tags: [JavaScript, JS, Google, V8]
redirect_from:
  - /2018/03/15
---
The Internet continues to be one of the most powerful forces shaping the modern world. From business to recreation, the Internet serves all. For developers, if you’re trying a nexus point that connects all the dots of this complicated system, you’ll inevitably end up running into JavaScript. From humble beginnings JavaScript rose from a language that was meant to manipulate the DOM to a full-fledged server-side language with countless modules and a few frameworks to boot. With the ubiquity of language across the web, I became interested in what “drives” JavaScript. Through my research I learned what a JavaScript engine is, what its mission is and what the problem space is. For the purposes of this post, I specifically looked at how Google has tried to solve the problem. I’d like to take a look at the history of Google’s JavaScript engine called “V8” and what makes it special.

What is an engine in the context JavaScript? I was confused about this too. To understand what an engine’s job is, we need to understand how a computer executes instructions. Computers can’t understand the instructions of a higher level language like JavaScript (which reads more like human language). Without “translating” this higher level language to a lower-level language the computer won’t know how to execute the instructions you wrote in JavaScript. There are two main strategies for making this kind of “translation” happen, interpretation and compilation.

Now you hear a lot about languages being either “interpreted” or “compiled” but the truth is that this distinction is quite hazy. The real decision about which translation method gets applied depends on the context of the implementation. When a language is “interpreted” there exists an interpreter that essentially acts like a processor and executes your source code or byte code. When a language is “compiled” your source code is converted into CPU executable code through a compiler. What’s the different here? Both are running your program but like all things tech, there are tradeoffs. A compiled language will always run faster than an interpreted language since you are making optimizations during the compilation process. However, this incurs more memory overhead. The code that gets compiled will only run on your hardware and/or OS. If you compiled on your Windows computer and gave that same compiled code to your Mac, the program would not be executable on that other system. However, if you use an interpreter, you can give your source code to any machine or OS that has the interpreter installed and run it no problem. Interpreters offer great portability and low memory overhead but at the cost of performance. Interpreters interpret your source code line by line so not only will your program be executed more slowly but you won’t know you have errors until your program is actually running. There are more differences (and similarities) between the two paradigms but that’s about all you need to know to understand how V8 works at a high level.

So let’s now go into a little of the history of V8. The first version was released on September 2nd 2008 and developed by the Chromium Project as an open-source JavaScript engine. It was (and still is) written in C++. In 2010 a new compiling infrastructure called CrankShaft was introduced with speed improvements. In 2015 another compiler known as Turbofan was introduced for further optimization purposes. In 2016 the Ignition interpreter was added with the goal of reducing the memory overhead for small memory devices like smart phones. In 2017 the V8 team completely rehauled the pipeline to just include the Ignition interpreter and Turbofan compiler in an effort to streamline their infrastructure and become more flexible in the face of rapidly released JS features and optimizations. Recently V8 has become very involved in furthering the development and cooperaptibililty between V8 and NodeJS since Node is built on top of V8 and Node being the go-to runtime for JS applications.

So what makes V8 special? Well it’s fast and the V8 team has worked very hard in making it the fastest engine out there. The flow of the engine goes like this: Ignition (V8’s interpreter) will read your source code and do some preliminary and small scale optimizations. Once it’s done it spits out some bytecode which it then sends to TurboFan to optimize further and ultimately compile. This modular and flexible build flow make it so that V8 can be optimized for low-memory IoT devices and large enterprise-grade applications that require better performance. In addition to Ignition and TurboFan, V8’s garbage collection module is called Orinoco which parallelizes the process, making it much faster. With all these modules combined, you get the V8 engine. This system has been in development for over a decade and has undergone a lot of changes but the V8 team stays committed to making JavaScript a language that is fast and flexible. As the world becomes more connected through the Internet, the need for performant JavaScript will only become that much more important.
